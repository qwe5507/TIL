# 카프카 기초

## 아파치 카프카 개요 및 설명
### 카프카 적용 전
![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/72dc89aa-1638-4953-a614-0e5736f2a3cf)

데이터를 전송할 떄 위와 같이 `데이터를 전송하는 소스 애플리케이션`과 `데이터를 받는 타겟 애플리케이션`으로 나뉜다.

![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/e32f67d0-a543-4a4e-93d0-e27649cc61b1)
![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/06c07666-6aa3-4be0-bdd2-7fba4479c45f)

소스 애플리케이션과 타겟 애플리케이션이 많아 질수록 데이터 전송 라인이 많아진다.
- 배포와 장애에 대응하기 어렵다.
- 데이터 전송 포맷과 프로토콜의 파편화가 심해진다.
  - 추후 데이터 포맷 변경이 있을때, 유지보수하기 어렵다.

![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/fb558f92-5730-4a37-abf4-ef815cf236c7)

위와 같은 복잡함을 해결하기 위해 링크드인에서 내부적으로 개발, 현재는 오픈소스로 제공되고 있는 플랫폼이다.


### 카프카의 특징
카프카는 소스 애플리케이션과 타겟 애플리케이션의 커플링을 낮추게 위해 등장했다.

![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/3efb4e14-4de3-4cc8-867a-79b81eea45fe)

데이터 포맷의 제한이 거의 없다.

![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/881b6e10-9831-488c-a461-13d9553a6f40)
- 큐의 역할을 하는 토픽
- 프로듀서와 컨슈머는 라이브러리로 되어있어, 애플리케이션에서 구현가능하다.
- 고가용성
  - 서버 다운시에도 데이터 손실없이 복구 할 수 있다.
- 낮은 지연과 높은 처리량

## 토픽
- 데이터가 들어가는 공간을 토픽이라고 한다.
- 일반적인 AMQP와는 다르게 동작한다.

- 토픽은 여러개 생성할 수 있다.
- 토픽은 데이터베이스의 테이블이나 파일시스템의 폴더와 유사한 성질을 가진다.

- 하나의 토픽은 여러개의 파티션으로 나뉠수 있다.
- 첫번쨰 파티션 번호는 0번부터 시작된다.
- 유지보수에 용이하게 토픽 이름을 짓는것이 좋다.

![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/ad699020-0dab-4575-970f-f21a173aa58e)
- 데이터는 파티션 안쪽부터 차곡차곡 쌓이게 된다

![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/e63dfff0-37b5-4f23-884a-5f88a46d9c53)
- 컨슈머가 데이터를 가져갈떈 파티션안의 가장 오래된 순서로 가져간다.
- 데이터가 더이상 존재하지 않으면 컨슈머는 또다른 데이터가 들어올 떄까지 기다린다.

![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/49d80025-b427-4610-9afa-efe7f954a476)
- 컨슈머가 데이터를 가져가도 데이터는 삭제되지 않고 파티션에 남아 있는다.

![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/008f37a5-6c47-407a-8142-ec625498132f)

- 다른 컨슈머가 동일 데이터에 대해 다시 처리할 수 있다.
  - 컨슈머 그룹이 다르고 `auto.offset.reset=earliest`여야 한다.
- 위 와 같이 동일 데이터에 대해 한 컨슈머는 ES에 저장하고, 다른 컨슈머는 Hadoop에 저장 할 수 있다.

### 파티션이 두개 일 경우
![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/47cbce10-0c31-4907-ab2f-ec1f34f3df14)

- 키 값이 없는 경우 `라운드 로빈`으로 할당
- 키 값이 있는 경우 키의 `해쉬값으로 파티션을 찾아 할당`

### 파티션은 늘릴 수 있지만 줄일 수 없음
![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/46c94d12-ffc4-41c2-82a7-5c80c7f0c00e)

- 파티션을 늘리는 이유는?
  - 컨슈머의 갯수를 늘려서 데이터 처리를 분산 시킬수 있다.
 
### 파티션의 데이터는 언제 삭제될까?
![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/cf2f5ddf-cf92-4bb4-867c-7634f427444e)

- 옵션에 따라 다르다.
  - 레코드가 저장되는 최대시간과 크기를 지정 할 수 있다.
  - 일정한 기간 혹은 용량동안 데이터를 저장하여 적절하게 데이터가 삭제될 수 있게 조정
 
---
## Broker, Replication, ISR
- 카프카를 운영하는데 `Broker`, `Replication`, `ISR`은 중요한 역할을 합니다.
- Replication은 카프카 아키텍처의 핵심이다.
  - 카프카의 고가용성을 위해

### 카프카 브로커
- `카프카가 설치되어 있는 서버 단위`
  - 보통 3개 이상의 broker로 구성하여 사용하는 것을 권장

### 레플리케이션과 ISR
![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/4ef5065b-d579-443d-bf01-c507279c5b3c)
- 만약 파티션이 1개, replication이 1인 topic, 브로커가 3대라면 브로커 3대 중 1대에 해당 토픽의 정보(데이터)가 저장된다.

![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/f0b0c702-ad6e-4915-911a-b1337abb660e)

- replication은 파티션의 복제를 뜻한다.
  - replication 1 : 파티션은 1개만 존재한다.
  - replication 2 : 원본 파티션 하나, 복제 파티션 하나가 존재한다.

![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/d12f3322-2145-41be-9607-06b13d7c1771)

- 브로커의 갯수에 따라, replication개수가 제한된다.
  - 브로커 개수가 3이면 replication은 4가 될 수 없다.

![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/79e70808-ffd5-4259-ab89-6fbe5df83d28)

- 원본 파티션을 Leader partition, 복제 파티션들을 Follower partition이라고 부른다.
 
![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/4d8c471e-8331-423c-8ea3-ee56e5b61542)

- Leader partition, Follower partition을 합쳐서 In Sync Replica(ISR)라고 볼 수 있다.

- **왜 replication을 사용할까?**
  - 파티션의 고가용성을 위해 사용 된다.
  - ![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/622efbc1-db03-4cf5-9f17-f8e3a7e2e28c)
  - 위와 같이 브로커가 3개, 파티션1, replication1인 토픽에서 오류가 발생하면 해당 파티션은 복구 할 수 없다.
  - ![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/6f09d1e9-44f8-46d0-8581-ea021f1ca301)
  - 브로커 1개가 죽더라도, 복제본인 Follwer partition이 존재하므로, 복제본으로 복구가 가능하다.
  - 남은 Follwer partition이 Leader partition 역할을 승계 한다.

### 레플리케이션과 ack옵션
- **Leader partition과 Follwer partition의 역할을 무엇일까?**
  - Producer가 토픽의 partition에 데이터를 전달 할떄, 전달받는 주체가 바로 Leader partition이다.
  - Producer에는 ack라는 옵션이 있다.
    - partition의 replication과 관련이 있다.
    - ack는 `0`, `1`, `all`중 하나를 선택하여 설정 할 수 있다.
    - `ack : 0`
      - ![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/c7882c05-3bea-41d5-b251-b67dcff85d3d)
      - ack가 0일 경우 Producer는 Leader partition에 데이터를 전송하고 응답 값을 받지 않는다.
      - Leader partition에 데이터가 정상적으로 전송됐는지, 나머지 partition에 정상적으로 복제되었는지 알 수 없다.
      - 속도는 빠르지만 데이터 유실 가능성이 있다.
    - `ack: 1`
      - ![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/e64501ba-8a95-4b79-93a3-fdfcd2bcf1ee)
      - ack가 1일 경우 Leader partition에 데이터를 전송하고, Leader partition이 데이터를 정상적으로 받았는지, 응답 값을 받는다.
      - 나머지 partition에 복제되었는지는 알수 없다.
      - Leader partition이 데이터를 받은 즉시 장애가 난다면 나머지 partition에 데이터가 미처 전송되지 못한 상태이므로 ack0 옵션과 마찬가지로 데이터 유실 가능성이 있다.
    - `ack : all`
      - ![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/f8c08edf-ecbd-497d-8ccb-4e55621a5de5)
      - ack가 all일 경우, 1옵션에 추가로 follower partition에 복제가 잘이루어 졌는지 응답 값을 받는다.
      - Leader partition에 데이터를 보낸 후, folllower partition에도 데이터가 저장되는지 확인하는 절차를 가진다.
      - 이 옵션의 경우, 데이터 유실은 없다고 보면 된다.
      - 0, 1 에 비해 확인하는 절차가 많아 속도가 현저히 느리다.
      - 금융 데이터와 같이 유실되면 안되는 데이터라면 느리더라도 ack all을 사용
        - ack 0, 1에 비해 느린것이다.

### 적정 레플리케이션 갯수 
- ![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/00b57335-4c7d-437c-af51-910935fb2603)
- replication이 무조건 많으면 좋아보이겠지만, replication이 많으면 브로커의 리소스 사용량도 늘어나게 된다.
- 카프카에 들어오는 데이터 량과 retention date(저장시간)을 잘 고려하여 replication 개수를 정해야 한다.
- ![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/a9aaeedb-73da-49c4-976f-3bc74a6741d1)
- **3개 이상의 브로커를 사용할 때 , replication을 3으로 설정하는 것을 추천한다.**

---
## 파티셔너란?
- 파티셔너는 카프카 프로듀서의 중요개념 중 하나이다.

![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/86b3b3e2-f85b-4463-a21f-5930b4fe1e2f)
- 프로듀서가 데이터를 전송하면 무조건 파티셔너를 통해 브로커로 데이터가 전송된다.
- `파티셔너는 데이터를 토픽의 어떤 파티션에 넣을지 결정하는 역할을 한다.`
- 레코드에 포함된 메시지 키, 값에 따라 파티션의 위치가 결정된다.
- 프로듀서를 사용 할때 파티셔너를 따로 설정하지 않는다면, `UniformStickyPartitioner`로 설정이 된다.
- 이 파티셔너는 메시지 키가 있을때, 없을때 다르게 동작한다.
- **메시지 키가 있는 경우**
  - ![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/2e297fbb-132e-46eb-9c8b-be62b936b802)
  - 메시지키를 가진 레코드는 파티셔너에 의해서 특정한 해쉬값이 생성된다.
  - 이 해쉬값을 기준으로 어느 파티션으로 들어갈지 결정되게 된다.
  - ![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/08f493a1-29ed-4cef-acf7-f2113df162f2)
  - 예를들어 파티션이 2개 있는경우, 파티셔너의 해쉬로직에 의해서 위와 같이 할당된다.
  - 동일한 메시지 키를 가진 레코드는 동일한 해쉬 값을 만들기 때문에 항상 같은 파티션에 할당된다.
    - 동일하 메시지 키를 가진 레코드들은 동일한 파티션에 들어가기떄문에, 순서를 지켜 처리할 수있다는 장점이 있다.
    > 예를들어 `서울`이라는 키를 가진 메시지를 계속보내면 항상 동일한 파티션에 순서대로 들어가기 떄문에 컨슈머는 서울이라는 레코드를 순서를 지켜서 데이터를 처리 할 수 있다.
    > 파티션 한개의 내부에서는 큐처럼 동작한다.
- **메시지 키가 없는 경우**
  - 라운드로빈으로 파티션에 들어간다.
  - 전통적인 라운드로빈 방식과 조금 다르게, `UniformStickyPartitioner`는 프로듀서에서 배치로 모을 수있는 최대한의 레코드를 모아서 파티션으로 보낸다.
  - 배치 단위로 데이터를 보낼때 파티션에 라운드로빈 방식 데이터를 넣게 된다.

- 카프카에서는 커스텀 파티셔너를 만들 수 있게, Partitioner 인터페이스를 제공
- Partitioner 인터페이스를 활용해서 Partitioner클래스를 만들면 메시지 키, 값, 토픽 이름에 따라 어느 파티션에 데이터를 보낼지 커스텀하게 정할 수 있다.
- **언제 커스텀 파티셔너가 필요할까?**
  - vip고객을 위해 데이터 처리를 조금더 빠르게 처리해주기 위해, 파티셔너를 통해 처리량을 늘릴 수 있다.
    > 10개의 파티션이 있을때, 커스텀 파티셔너로 8개는 vip고객의 데이터, 2개의 파티션에는 일반고객의 형태로 구성할 수 있다.

## 컨슈머 랙(Consumer Lag)이란?
- 프로듀서가 파티션에 데이터를 적재하면 각 데이터에는 오프셋이라고 하는 숫자가 붙게 된다.
- ![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/58bf1d22-552c-4d57-b9b0-37d9dec667b3)
- 파티션이 1개인 토픽에 프로듀서가 데이터를 넣을 경우 0부터 차례대로 숫자가 매겨진다.
- ![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/b712f589-8aef-43b4-b1fe-a0fbe5dc89c1)
- **프로듀사가 넣은 오프셋, 컨슈머가 가져간 데이터의 오프셋 이 두개의 오프셋 간의 차이를 `컨슈머 랙`이라고 한다.**
  - 랙의 숫자를 통해 현재 해당 토픽에 대해 프로듀서와 컨슈머의 상태에 대해 유추할 수 있다.
  - 주로 컨슈머의 상태에 대해 볼떄 사용한다.
- 토픽에 여러 파티션이 있을경우, **lag은 여러개가 존재할 수 있다.**
- ![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/fe0c1d2a-2c77-412b-a9b5-b545ca4f6db0)
- 컨슈머 그룹이 1개이고, 파티션이 2개인 토픽에서 데이터를 가져간다면, 랙은 2개가 측정 될 수 있다.
  - 한개의 토픽과 컨슈머 그룹에 대한 lag이 여러개 존재 할 수 있을때, 그 중 높은 숫자의 lag을 `records-lag-max`라고 부른다.
- 컨슈머가 성능이 떨어지거나, 비정상적인 동작을하면 lag이 필연적으로 발생한다.

## 컨슈머 랙 모니터링 애플리케이션, 카프카 버로우(Burrow)
- 카프카 버로우는 컨슈머 랙을 모니터링 하기위한 오픈소스이다.
- kafka-client라이브러리를 사용하여 구현한 카프카 컨슈머 객체를 통해 Lag정보를 가져올 수 있다.
  > 실시간으로 확인하고 싶다면, ELK, influxdb -> 그라파나 대쉬보드를 통해 모니터링 해야함
- 컨슈머 로직 단에서 lag을 수집하는 것은 컨슈머 상태에 의존하여, 운영을 까다롭게 한다.
- 버로우는 컨슈머 lag 모니터링을 도와주는 독립적인 애플리케이션이다.

**Burrow의 특징**

1.**멀티 카프카 클러스터 지원**
  - 실무에선 대부분 2개 이상의 클러스터를 운영하고 있는데, 클러스터가 여러개더라도 Burrow application 한개만 실행해서 연동한다면 카프카 클러스터드들에 붙은 컨슈머 lag을 모두 모니터링 할 수 있다.
2.**Sliding window를 통한 Consumer status 확인**
  - 슬라이딩 윈도우를 통해서 컨슈머의 status를 ‘ERROR’, ‘WARNING’, ‘OK’로 구분합니다.
  - 데이터의 양이 일시적으로 많아져서 consumer offset이 증가되고 있으면 ‘WARNING’으로 정의됩니다.
  - 데이터의 양이 많아지고 있는데 consumer가 데이터를 가져가지 않으면 ‘ERROR’로 정의하여 실제로 컨슈머가 문제가 있는지 여부를 알 수 있습니다.
3.**HTTP api 제공**
  - 위와 같은 정보들을 Burrow에서 정의한 HTTP api를 통해 조회 할 수 있습니다.

## 카프카, 레빗엠큐, 레디스 큐의 차이점
- 메시징 플랫폼은 `메시지 브로커`, `이벤트 브로커`로 나뉜다.
  - 메시지 브로커는 이벤트 브로커의 역할을 할수 없지만, 이벤트 브로커는 메시지 브로커 역할을 할 수 있다.

1. 메시지 브로커
   - 대규모 메시지 기반, 미들웨어 아키텍처에서 사용
     > 미들웨어란, 서비스하는 애플리케이션들을 보다 효율적으로 연결하는 소프트웨어를 뜻한다.
   - 메시징 플랫폼, 인증 플랫폼, 데이터베이스와 같은 것들이 미들웨어
   - 메시지 브로커에 있는 큐에 데이터를 보내고 받는 프로듀서와 컨슈머를 통해 메시지를 통신하고 네트워크를 맺는다.
   - **메시지를 받아서 처리하고 나면, 즉시 또는 짧은 시간내에 삭제 된다.**

2. 이벤트 브로커 
  - 이벤트 또는 메시지라 불리는 레코드를 딱하나만 보관하고, 인덱스를 통해 개별 엑세스를 관리한다.
  - 업무상 필요한 시간 동안 이벤트를 보존할 수 있다.
- 이벤트 브로커는 메시지 브로커와 달리 데이터를 삭제 하지 않는다. 
- 이벤트 브로커는 서비스에서 나오는 이벤트를 큐에 저장한다.
  - 딱 한번 일어난 이벤트 데이터를 브로커에 저장함으로서, 단일 진실 공급원으로 사용 할 수 있다.
  - 장애가 발생 했을떄, 장애가 발생한 지점부터 재 처리 가능하다.
  - 많은 양의 스트림 데이터를 효과적으로 처리 할 수 있다.

메시지 브로커는 `레디스 큐`나 `래빗엠큐`, 이벤트 브로커는 `카프카`나 `키네시스`를 예로 들 수 있다. 


## 카프카 프로듀서

### 카프카 프로듀서의 역할 
  - Topic에 해당하는 메시지를 생성
  - 특정 Topic으로 데이터를 publish 
  - 카프카 broker로 데이터 전송 시, 처리 실패/재시도

- 토픽에 파티션을 추가하는 순간, 키-파티션의 일관성은 보장되지 않는다.
  > 키를 사용한다면 파티션을 추가로 생성하지 않는것을 추천한다.

## 카프카 컨슈머

### 카프카 컨슈머의 역할 
  - Topic의 partition으로 부터 데이터 polling
  > 컨슈머가 카프카의 데이터를 가져오는 것을 `폴링`이라고 한다.
  - Partition offset 위치 기록(commit)
  - 컨슈머가 여러개일 경우, 컨슈머 그룹을 통해 병렬 처리가능

![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/838c1f91-c176-4f97-b451-70802f3c8f5b)
- offet은 토픽별로 그리고 파티션별로 별개로 지정된다.
- 컨슈머가 데이터를 어느 지점까지 읽었는지 확인하는 용도
- 컨슈머가 데이터를 읽으면 offset을 commit한다.
  - 카프카의 `__consumer_offset`토픽에 offset정보를 저장한다.
  - 컨슈머가 어디까지 읽었는지 `__consumer_offset`에 저장되어 있기 때문에, 컨슈머를 재기동해도 시작위치를 복구 할 수 있다. 

### Multiple consumer
![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/eacd68fd-f335-43c9-a581-abf885f98e98)
- 파티션이 2개, 컨슈머가 한개인 경우 2개의 파티션에서 데이터를 가져 간다.

![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/f8df2239-d57f-41b5-85eb-95db55eabd9a)
- 파티션이 2개, 컨슈머가 2개인 경우, 각 컨슈머가 각각 파티션을 할당하여 가져간다.
  
![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/05de9664-8aa1-45b3-8398-0af10e026737)
- 파티션이 2개, 컨슈머가 3개인 경우 더이상 할당될 파티션이 없어 동작하지 않는다.
  - **여러 파티션을 가진 토픽에 대해 컨슈머를 병렬 처리하고 싶다면, 컨슈머를 파티션 개수보다 적은 개수로 실행해야 한다.**
 
### Different groups
- 각기 다른 컨슈머 그룹일 경우 다른 컨슈머 그룹에 영향을 미치지 않는다.

![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/78af76e8-2a70-414a-b720-b47f4f8e0ce9)
- 특정 파티션의 데이터를 elk에 저장하다가, 다른 파티션 그룹이 haddop에 저장해도 그룹간에 영향을 끼치지 않는다.
  - `__consumer_offset`에는 컨슈머 그룹별, 토픽별로 offset을 나누어 저장하기 때문에
- 하나의 토픽으로 들어온 데이터를 다양한 역할을 하는 컨슈머들이 각자 원하는대로 처리할 수 있다.
  
---
> 카프카 클라이언트 버전과 카프카 브로커 버전이 모든 하위호환성을 지원하지 않는다.
> 호환성을 확인하여 사용해야 한다.

## 카프카 스트림즈란?
- 카프카는 분산 이벤트 스트리밍 플랫폼으로써, 프로듀서와 컨슈머를 사용해서 데이터를 보내고 가져와서 처리할 수 있다. 수많은 국내외 기업에서 카프카를 사용하고 있으며, 자바/고랭/파이썬과 같은 언어들을 사용해서 프로듀서와 컨슈머를 개발하고 있다. 
  하지만 컨슈머를 사용해서 데이터를 처리하는 것보다 더 안전하고 빠르면서도 다양한 기술을 사용할 수 있는 것이 있다. 바로 '카프카 스트림즈Kafka Streams'이다.
- 카프카 스트림즈는 카프카에서 공식적으로 제공하는 자바 라이브러리로써, 토픽에 있는 데이터를 낮은 지연과 빠른 속도로 처리할 수 있다. 스트림즈는 라이브러리로 제공되는 것이므로, 자바/스칼라/코틀린과 같은 JVM 기반의 언어 중 하나를 선택해서 개발하면 된다. 또한 스프링부트 위에 올려도 되며, 순수 자바 애플리케이션에 라이브러리를 추가시켜서 동작하게 배포할 수도 있다. 

### 아파치 카프카 스트림즈의 장점
1. **카프카와 완벽 호환된다**
  - 대부분의 기업은 카프카를 이벤트 저장소로 사용하고 저장된 데이터를 spark(스파크) 또는 logstash(로그스태시)와 같은 툴로 연동할 것이다. 이런 외부 오픈소스툴의 문제점은 빠르게 발전하는 오픈소스 카프카의 버전을 따라가지 못한다는 것이다. 하지만 kafka streams는 카프카가 새롭게 릴리즈 될 때마다 카프카 클러스터와 완벽하게 호환되는 최신의 기능들을 갖는다. 따라서 카프카에 보안 기능이나 ACL 같은 것들이 붙어 있더라도 완벽하게 호환 가능하며, 성능 개선도 빠르게 이루어지고 있다. 무엇보다도 데이터가 유실되거나 중복 처리되지 않고 딱 한 번만 처리될 수 있는 강력한 기능을 가지고 있다. 이는 카프카와 연동하는 이벤트 프로세싱 도구 중에 거의 유일하다고 볼 수 있다. 따라서 카프카를 사용하고 있고 데이터를 안전하고 빠르게 처리하고 싶다면 apache kafka streams를 1순위로 고려해야 한다.

2. **스케줄링 도구가 필요 없다.**
  - 카프카와 연동하는 스트림 프로세싱 툴로써 가장 많이 그리고 가장 널리 사용하는 것이 spark stream(스파크 스트림)일 것이다. 스파크 스트리밍 또는 스파크 구조적 스트림을 사용하면, 카프카와 연동하여 마이크로 배치 처리를 하는 이벤트 데이터 애플리케이션을 만들 수 있다. 하지만 문제는 스파크를 운영하기 위해서는 yarn이나 mesos와 같은 클러스터 관리자나 리소스 매니저 같은 것들이 필요하다는 점이다. 그리고 클러스터를 운영하기 위해 대규모 장비들도 구축해야 한다. 반면 스트림즈를 이용하면 스케줄링 도구는 전혀 필요가 없다. 개발한 스트림즈 애플리케이션은 컨슈머 애플리케이션이나 WAS 애플리케이션을 배포하는 것처럼 원하는 만큼 배포하면 된다. 만약 적은 양의 데이터를 처리해야 한다면 2개 정도의 스트림즈 애플리케이션을 띄워서 운영하면 되고, 데이터를 많이 처리해야 한다면 자연스럽게 scale out해서 10개 내지 20개의 애플리케이션을 배포하면 된다.

3. **스트림즈 DSL과 프로세서 API를 제공**
스트림즈를 구현하는 방법은 크게 두 가지가 있다. 
  - 대부분의 경우는 스트림즈 DSL을 사용해서 구현할 수 있다. 스트림즈 DSL은 이벤트 기반 데이터 처리를 할 때 필요한 다양한 기능들을 map, join, window와 같은 메서드를 통해 제공하기 때문에 사용하기 편하다.
  - 스트림즈 DSL에서 없는 기능이라면, 프로세서 API를 이용해서 로직을 작성하면 된다. 다만, 대부분의 기능이 이미 스트림즈 DSL에 있으므로 아직까지는 프로세서 API를 사용할 필요가 없을 것이다. 그만큼 스트림즈 DSL은 강력한 기능을 내포하고 있다.

  - 또한 스트림즈 DSL에서 제공하는 KStream, KTable, GlobalKTable은 그 어디서도 볼 수 없는 독특한 스트림 처리 개념이다. 카프카를 스트림 데이터 처리뿐만 아니라 대규모 key-value 저장소로 사용할 수 있는 기능이다. 따라서 카프카를 더 풍부한 기능으로 사용하고 싶다면 카프카 스트림즈는 필수이다.

4. **로컬 상태저장소를 사용한다.**

실시간으로 들어오는 데이터를 처리하는 방식은 크게 두 가지가 있다.

1. 비상태 기반 처리 (Stateless)
   - 필터링이나 데이터를 변환하는 처리이다. 데이터가 들어오는 족족 바로 처리하고 프로듀스하면 되기 때문에 데이터 유실이나 중복이 발생할 확률이 적으며, 쉽게 개발할 수 있다.
2. 상태 기반 처리 (Stateful)
   - 상태 기반 처리를 직접 구현하는 것은 상당히 어렵다. 왜냐하면 window, join, aggregation(취합)과 같은 처리는 이전에 받았던 데이터를 프로세스가 메모리에 저장하고 있으면서 다음 데이터를 참조해서 처리해야 하기 때문이다. 이처럼 상태 기반 분산 프로세스를 구현하는 것은 매우 허들이 높은데, 이런 어려움을 극복해주는 것이 스트림즈이다. 스트림즈는 로컬의 rocksdb를 사용해서 상태를 저장하고, 이 상태에 대한 변환 정보는 카프카의 변경로그(changelog) 토픽에 저장한다. 따라서 스트림즈를 사용하면 프로세스에 장애가 발생하더라도 그 상태가 안전하게 저장되기 때문에 자연스럽게 장애 복구가 될 수 있다. 엄청나게 강력한 기능이다.

### Streams 코드 예시
```java
KStream<String, String> paymentStream = builder.stream("payment");
KStream<String, String> filteredStream = paymentStream.filter((key, value) -> key.equals("unknown"));
filteredStream.to("unknown-payment");
```

위 코드는 payment 토픽에 메시지 키가 unknown인 데이터를 필터링해서 unknown-payment 토픽으로 보내는 스트림즈 코드이다. 기존처럼 컨슈머로 폴링하거나 프로듀서를 어렵게 구현할 필요가 없으므로 매우 쉽다.

카프카 스트림즈는 이벤트 기반 처리에 있어서 아직 국내에서는 익숙하지 않은 기술이지만, 실시간으로 끊임없이 발생하는 데이터를 처리해야 할 때 어떤 프레임워크로 처리해야할지 고민이라면, 카프카 스트림즈에 대해 공부한 후 도입 여부를 고려하는 것이 좋을 것이다.


## 카프카 커넥트
- 더 간편하게 효율적으로 데이터파이프라인을 구축하는 방법이다.
- 카프카에서 공식적으로 제공하는 컴포넌트 중 하나
   
- 카프카 커넥트는 `커넥트`와 `커넥터`로 이루어져 있다.
  - **카프카 커넥트**
    - 커넥터를 동작하도록 실행해주는 프로세스
    - 프레임워크
    - 파이프라인으로 동작하는 커넥터를 동작하기 위해서는 커넥트를 실행시켜야 한다.
      
    - 커넥트는 `단일 실행모드 커넥트`와 `분산 모드 커넥트`로 나뉜다.
      - **단일 실행모드 커넥트**
        - 간단한 데이터 파이프라인을 구성하거나, 개발용으로 사용한다.
       
      - **분산 모드 커넥트**
        - 여러개의 커넥트를 하나의 클러스터로 묶어 운영하는 방식
  
  - **카프카 커넥터**
    - 커넥터는 데이터를 어디서(source) 복사하는지와, 어디에다(sink) 붙여넣어야 하는지를 정의한다.
    - 실질적으로 데이터를 처리하는 코드가 담긴 jar파일
    - 커넥트 안에 들어가는 플러그인의 한 종류이다.
    - 커넥터안에는 파이프라인에 필요한 여러가지 동작과 설정, 실행하는 메서드들이 포함되어 있다.
      > 토픽에서 오라클DB에 데이터를 저장하고 싶다면, 커넥터에 insert메서드를 구현하고 커넥터를 실행하는 방식으로 운영해야 한다.

    - 커넥터는 `싱크 커넥터`와 `소스 커넥터`로 나뉜다. 
      - **싱크 커넥터**
        - 특정 토픽에 있는 데이터를 오라클, mysql, ES와 같이 특정 저장소에 저장하는 역할을 한다.(컨슈머와 같은 역할)
        > ex) oracle에 데이터를 저장하고 싶으면 OracleSinkConnector로 지칭한다.
      - **소스 커넥터**
        - 데이터베이스로 부터 데이터를 가져와서 토픽에 넣는 역할 (프로듀서와 같은 역할)
          
  ### **커넥트와 커넥터의 관계**
  - ![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/e7a674c2-93c1-4c7d-9bf8-607f2acbd9dd)
  - 커넥트를 실행할 때 커넥터가 어디에 위치하는지 config파일에 위치를 지정해야 한다.
  >  커넥터 jar패키지가 있는 디렉토리를 config파일에 지정한다.
  - 설정 후, 커넥트를 실행하면 jar파일의 커넥터들을 함께 모아서 커넥터를 실행할 수 있도록 준비상태에 돌입한다.
  - 실행중인 커넥트에 커넥터를 실행하려면 REST API를 통해서 커넥터를 실행 할 수 있다.
  - 커넥트를 활용하면, 파이프라인을 만들때 추가로 개발, 배포 과정 없이 REST API를 통해서 커넥터를 통한 파이프라인이 분산해서 생긴다.
    - ![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/50fc41ed-49a8-4eaf-8270-6418341a6506)
    - 예를들어 오라클 db에 데이터를 저장하는 OracleSinkConnector가 있고, 특정 토픽에 있는 데이터를 특정 테이블로 보낼때, 위와 같은 json으로 설정을 만든다. 그리고 이 body를 REST API를 통해 커넥트에 명령을 내린다.
    - 커넥트에 파이프라인이 생성된다.
    - 개발하고, 구축하고, 모니터링을 구축하는 과정을 커넥트에서는 템플릿 형태로 커넥터 개발 후 rest api를 통해 반복적으로 생성 할 수 있다.
  - 커넥터는 직접 개발해도 되지만, 오픈소스 커넥터가 많이 존재한다.

---
## ref
- https://www.inflearn.com/course/%EC%95%84%ED%8C%8C%EC%B9%98-%EC%B9%B4%ED%94%84%EC%B9%B4-%EC%9E%85%EB%AC%B8/dashboard
