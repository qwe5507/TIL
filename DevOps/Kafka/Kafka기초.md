# 카프카 기초

## 아파치 카프카 개요 및 설명
### 카프카 적용 전
![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/72dc89aa-1638-4953-a614-0e5736f2a3cf)

데이터를 전송할 떄 위와 같이 `데이터를 전송하는 소스 애플리케이션`과 `데이터를 받는 타겟 애플리케이션`으로 나뉜다.

![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/e32f67d0-a543-4a4e-93d0-e27649cc61b1)
![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/06c07666-6aa3-4be0-bdd2-7fba4479c45f)

소스 애플리케이션과 타겟 애플리케이션이 많아 질수록 데이터 전송 라인이 많아진다.
- 배포와 장애에 대응하기 어렵다.
- 데이터 전송 포맷과 프로토콜의 파편화가 심해진다.
  - 추후 데이터 포맷 변경이 있을때, 유지보수하기 어렵다.

![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/fb558f92-5730-4a37-abf4-ef815cf236c7)

위와 같은 복잡함을 해결하기 위해 링크드인에서 내부적으로 개발, 현재는 오픈소스로 제공되고 있는 플랫폼이다.


### 카프카의 특징
카프카는 소스 애플리케이션과 타겟 애플리케이션의 커플링을 낮추게 위해 등장했다.

![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/3efb4e14-4de3-4cc8-867a-79b81eea45fe)

데이터 포맷의 제한이 거의 없다.

![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/881b6e10-9831-488c-a461-13d9553a6f40)
- 큐의 역할을 하는 토픽
- 프로듀서와 컨슈머는 라이브러리로 되어있어, 애플리케이션에서 구현가능하다.
- 고가용성
  - 서버 다운시에도 데이터 손실없이 복구 할 수 있다.
- 낮은 지연과 높은 처리량

## 토픽
- 데이터가 들어가는 공간을 토픽이라고 한다.
- 일반적인 AMQP와는 다르게 동작한다.

- 토픽은 여러개 생성할 수 있다.
- 토픽은 데이터베이스의 테이블이나 파일시스템의 폴더와 유사한 성질을 가진다.

- 하나의 토픽은 여러개의 파티션으로 나뉠수 있다.
- 첫번쨰 파티션 번호는 0번부터 시작된다.
- 유지보수에 용이하게 토픽 이름을 짓는것이 좋다.

![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/ad699020-0dab-4575-970f-f21a173aa58e)
- 데이터는 파티션 안쪽부터 차곡차곡 쌓이게 된다

![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/e63dfff0-37b5-4f23-884a-5f88a46d9c53)
- 컨슈머가 데이터를 가져갈떈 파티션안의 가장 오래된 순서로 가져간다.
- 데이터가 더이상 존재하지 않으면 컨슈머는 또다른 데이터가 들어올 떄까지 기다린다.

![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/49d80025-b427-4610-9afa-efe7f954a476)
- 컨슈머가 데이터를 가져가도 데이터는 삭제되지 않고 파티션에 남아 있는다.

![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/008f37a5-6c47-407a-8142-ec625498132f)

- 다른 컨슈머가 동일 데이터에 대해 다시 처리할 수 있다.
  - 컨슈머 그룹이 다르고 `auto.offset.reset=earliest`여야 한다.
- 위 와 같이 동일 데이터에 대해 한 컨슈머는 ES에 저장하고, 다른 컨슈머는 Hadoop에 저장 할 수 있다.

### 파티션이 두개 일 경우
![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/47cbce10-0c31-4907-ab2f-ec1f34f3df14)

- 키 값이 없는 경우 `라운드 로빈`으로 할당
- 키 값이 있는 경우 키의 `해쉬값으로 파티션을 찾아 할당`

### 파티션은 늘릴 수 있지만 줄일 수 없음
![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/46c94d12-ffc4-41c2-82a7-5c80c7f0c00e)

- 파티션을 늘리는 이유는?
  - 컨슈머의 갯수를 늘려서 데이터 처리를 분산 시킬수 있다.
 
### 파티션의 데이터는 언제 삭제될까?
![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/cf2f5ddf-cf92-4bb4-867c-7634f427444e)

- 옵션에 따라 다르다.
  - 레코드가 저장되는 최대시간과 크기를 지정 할 수 있다.
  - 일정한 기간 혹은 용량동안 데이터를 저장하여 적절하게 데이터가 삭제될 수 있게 조정
 
---
## Broker, Replication, ISR
- 카프카를 운영하는데 `Broker`, `Replication`, `ISR`은 중요한 역할을 합니다.
- Replication은 카프카 아키텍처의 핵심이다.
  - 카프카의 고가용성을 위해

### 카프카 브로커
- `카프카가 설치되어 있는 서버 단위`
  - 보통 3개 이상의 broker로 구성하여 사용하는 것을 권장

### 레플리케이션과 ISR
![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/4ef5065b-d579-443d-bf01-c507279c5b3c)
- 만약 파티션이 1개, replication이 1인 topic, 브로커가 3대라면 브로커 3대 중 1대에 해당 토픽의 정보(데이터)가 저장된다.

![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/f0b0c702-ad6e-4915-911a-b1337abb660e)

- replication은 파티션의 복제를 뜻한다.
  - replication 1 : 파티션은 1개만 존재한다.
  - replication 2 : 원본 파티션 하나, 복제 파티션 하나가 존재한다.

![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/d12f3322-2145-41be-9607-06b13d7c1771)

- 브로커의 갯수에 따라, replication개수가 제한된다.
  - 브로커 개수가 3이면 replication은 4가 될 수 없다.

![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/79e70808-ffd5-4259-ab89-6fbe5df83d28)

- 원본 파티션을 Leader partition, 복제 파티션들을 Follower partition이라고 부른다.
 
![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/4d8c471e-8331-423c-8ea3-ee56e5b61542)

- Leader partition, Follower partition을 합쳐서 In Sync Replica(ISR)라고 볼 수 있다.

- **왜 replication을 사용할까?**
  - 파티션의 고가용성을 위해 사용 된다.
  - ![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/622efbc1-db03-4cf5-9f17-f8e3a7e2e28c)
  - 위와 같이 브로커가 3개, 파티션1, replication1인 토픽에서 오류가 발생하면 해당 파티션은 복구 할 수 없다.
  - ![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/6f09d1e9-44f8-46d0-8581-ea021f1ca301)
  - 브로커 1개가 죽더라도, 복제본인 Follwer partition이 존재하므로, 복제본으로 복구가 가능하다.
  - 남은 Follwer partition이 Leader partition 역할을 승계 한다.

### 레플리케이션과 ack옵션
- **Leader partition과 Follwer partition의 역할을 무엇일까?**
  - Producer가 토픽의 partition에 데이터를 전달 할떄, 전달받는 주체가 바로 Leader partition이다.
  - Producer에는 ack라는 옵션이 있다.
    - partition의 replication과 관련이 있다.
    - ack는 `0`, `1`, `all`중 하나를 선택하여 설정 할 수 있다.
    - `ack : 0`
      - ![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/c7882c05-3bea-41d5-b251-b67dcff85d3d)
      - ack가 0일 경우 Producer는 Leader partition에 데이터를 전송하고 응답 값을 받지 않는다.
      - Leader partition에 데이터가 정상적으로 전송됐는지, 나머지 partition에 정상적으로 복제되었는지 알 수 없다.
      - 속도는 빠르지만 데이터 유실 가능성이 있다.
    - `ack: 1`
      - ![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/e64501ba-8a95-4b79-93a3-fdfcd2bcf1ee)
      - ack가 1일 경우 Leader partition에 데이터를 전송하고, Leader partition이 데이터를 정상적으로 받았는지, 응답 값을 받는다.
      - 나머지 partition에 복제되었는지는 알수 없다.
      - Leader partition이 데이터를 받은 즉시 장애가 난다면 나머지 partition에 데이터가 미처 전송되지 못한 상태이므로 ack0 옵션과 마찬가지로 데이터 유실 가능성이 있다.
    - `ack : all`
      - ![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/f8c08edf-ecbd-497d-8ccb-4e55621a5de5)
      - ack가 all일 경우, 1옵션에 추가로 follower partition에 복제가 잘이루어 졌는지 응답 값을 받는다.
      - Leader partition에 데이터를 보낸 후, folllower partition에도 데이터가 저장되는지 확인하는 절차를 가진다.
      - 이 옵션의 경우, 데이터 유실은 없다고 보면 된다.
      - 0, 1 에 비해 확인하는 절차가 많아 속도가 현저히 느리다.
      - 금융 데이터와 같이 유실되면 안되는 데이터라면 느리더라도 ack all을 사용
        - ack 0, 1에 비해 느린것이다.

### 적정 레플리케이션 갯수 
- ![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/00b57335-4c7d-437c-af51-910935fb2603)
- replication이 무조건 많으면 좋아보이겠지만, replication이 많으면 브로커의 리소스 사용량도 늘어나게 된다.
- 카프카에 들어오는 데이터 량과 retention date(저장시간)을 잘 고려하여 replication 개수를 정해야 한다.
- ![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/a9aaeedb-73da-49c4-976f-3bc74a6741d1)
- **3개 이상의 브로커를 사용할 때 , replication을 3으로 설정하는 것을 추천한다.**

---
## 파티셔너란?
- 파티셔너는 카프카 프로듀서의 중요개념 중 하나이다.

![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/86b3b3e2-f85b-4463-a21f-5930b4fe1e2f)
- 프로듀서가 데이터를 전송하면 무조건 파티셔너를 통해 브로커로 데이터가 전송된다.
- `파티셔너는 데이터를 토픽의 어떤 파티션에 넣을지 결정하는 역할을 한다.`
- 레코드에 포함된 메시지 키, 값에 따라 파티션의 위치가 결정된다.
- 프로듀서를 사용 할때 파티셔너를 따로 설정하지 않는다면, `UniformStickyPartitioner`로 설정이 된다.
- 이 파티셔너는 메시지 키가 있을때, 없을때 다르게 동작한다.
- **메시지 키가 있는 경우**
  - ![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/2e297fbb-132e-46eb-9c8b-be62b936b802)
  - 메시지키를 가진 레코드는 파티셔너에 의해서 특정한 해쉬값이 생성된다.
  - 이 해쉬값을 기준으로 어느 파티션으로 들어갈지 결정되게 된다.
  - ![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/08f493a1-29ed-4cef-acf7-f2113df162f2)
  - 예를들어 파티션이 2개 있는경우, 파티셔너의 해쉬로직에 의해서 위와 같이 할당된다.
  - 동일한 메시지 키를 가진 레코드는 동일한 해쉬 값을 만들기 때문에 항상 같은 파티션에 할당된다.
    - 동일하 메시지 키를 가진 레코드들은 동일한 파티션에 들어가기떄문에, 순서를 지켜 처리할 수있다는 장점이 있다.
    > 예를들어 `서울`이라는 키를 가진 메시지를 계속보내면 항상 동일한 파티션에 순서대로 들어가기 떄문에 컨슈머는 서울이라는 레코드를 순서를 지켜서 데이터를 처리 할 수 있다.
    > 파티션 한개의 내부에서는 큐처럼 동작한다.
- **메시지 키가 없는 경우**
  - 라운드로빈으로 파티션에 들어간다.
  - 전통적인 라운드로빈 방식과 조금 다르게, `UniformStickyPartitioner`는 프로듀서에서 배치로 모을 수있는 최대한의 레코드를 모아서 파티션으로 보낸다.
  - 배치 단위로 데이터를 보낼때 파티션에 라운드로빈 방식 데이터를 넣게 된다.

- 카프카에서는 커스텀 파티셔너를 만들 수 있게, Partitioner 인터페이스를 제공
- Partitioner 인터페이스를 활용해서 Partitioner클래스를 만들면 메시지 키, 값, 토픽 이름에 따라 어느 파티션에 데이터를 보낼지 커스텀하게 정할 수 있다.
- **언제 커스텀 파티셔너가 필요할까?**
  - vip고객을 위해 데이터 처리를 조금더 빠르게 처리해주기 위해, 파티셔너를 통해 처리량을 늘릴 수 있다.
    > 10개의 파티션이 있을때, 커스텀 파티셔너로 8개는 vip고객의 데이터, 2개의 파티션에는 일반고객의 형태로 구성할 수 있다.

## 컨슈머 랙(Consumer Lag)이란?
- 프로듀서가 파티션에 데이터를 적재하면 각 데이터에는 오프셋이라고 하는 숫자가 붙게 된다.
- ![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/58bf1d22-552c-4d57-b9b0-37d9dec667b3)
- 파티션이 1개인 토픽에 프로듀서가 데이터를 넣을 경우 0부터 차례대로 숫자가 매겨진다.
- ![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/b712f589-8aef-43b4-b1fe-a0fbe5dc89c1)
- **프로듀사가 넣은 오프셋, 컨슈머가 가져간 데이터의 오프셋 이 두개의 오프셋 간의 차이를 `컨슈머 랙`이라고 한다.**
  - 랙의 숫자를 통해 현재 해당 토픽에 대해 프로듀서와 컨슈머의 상태에 대해 유추할 수 있다.
  - 주로 컨슈머의 상태에 대해 볼떄 사용한다.
- 토픽에 여러 파티션이 있을경우, **lag은 여러개가 존재할 수 있다.**
- ![image](https://github.com/qwe5507/SEQ-ERD/assets/70142711/fe0c1d2a-2c77-412b-a9b5-b545ca4f6db0)
- 컨슈머 그룹이 1개이고, 파티션이 2개인 토픽에서 데이터를 가져간다면, 랙은 2개가 측정 될 수 있다.
  - 한개의 토픽과 컨슈머 그룹에 대한 lag이 여러개 존재 할 수 있을때, 그 중 높은 숫자의 lag을 `records-lag-max`라고 부른다.
- 컨슈머가 성능이 떨어지거나, 비정상적인 동작을하면 lag이 필연적으로 발생한다.

## 컨슈머 랙 모니터링 애플리케이션, 카프카 버로우(Burrow)
- 카프카 버로우는 컨슈머 랙을 모니터링 하기위한 오픈소스이다.
- kafka-client라이브러리를 사용하여 구현한 카프카 컨슈머 객체를 통해 Lag정보를 가져올 수 있다.
  > 실시간으로 확인하고 싶다면, ELK, influxdb -> 그라파나 대쉬보드를 통해 모니터링 해야함
- 컨슈머 로직 단에서 lag을 수집하는 것은 컨슈머 상태에 의존하여, 운영을 까다롭게 한다.
- 버로우는 컨슈머 lag 모니터링을 도와주는 독립적인 애플리케이션이다.

**Burrow의 특징**

1.**멀티 카프카 클러스터 지원**
  - 실무에선 대부분 2개 이상의 클러스터를 운영하고 있는데, 클러스터가 여러개더라도 Burrow application 한개만 실행해서 연동한다면 카프카 클러스터드들에 붙은 컨슈머 lag을 모두 모니터링 할 수 있다.
2.**Sliding window를 통한 Consumer status 확인**
  - 슬라이딩 윈도우를 통해서 컨슈머의 status를 ‘ERROR’, ‘WARNING’, ‘OK’로 구분합니다.
  - 데이터의 양이 일시적으로 많아져서 consumer offset이 증가되고 있으면 ‘WARNING’으로 정의됩니다.
  - 데이터의 양이 많아지고 있는데 consumer가 데이터를 가져가지 않으면 ‘ERROR’로 정의하여 실제로 컨슈머가 문제가 있는지 여부를 알 수 있습니다.
3.**HTTP api 제공**
  - 위와 같은 정보들을 Burrow에서 정의한 HTTP api를 통해 조회 할 수 있습니다.

## 카프카, 레빗엠큐, 레디스 큐의 차이점
- 메시징 플랫폼은 `메시지 브로커`, `이벤트 브로커`로 나뉜다.
  - 메시지 브로커는 이벤트 브로커의 역할을 할수 없지만, 이벤트 브로커는 메시지 브로커 역할을 할 수 있다.

1. 메시지 브로커
   - 대규모 메시지 기반, 미들웨어 아키텍처에서 사용
     > 미들웨어란, 서비스하는 애플리케이션들을 보다 효율적으로 연결하는 소프트웨어를 뜻한다.
   - 메시징 플랫폼, 인증 플랫폼, 데이터베이스와 같은 것들이 미들웨어
   - 메시지 브로커에 있는 큐에 데이터를 보내고 받는 프로듀서와 컨슈머를 통해 메시지를 통신하고 네트워크를 맺는다.
   - **메시지를 받아서 처리하고 나면, 즉시 또는 짧은 시간내에 삭제 된다.**

2. 이벤트 브로커 
  - 이벤트 또는 메시지라 불리는 레코드를 딱하나만 보관하고, 인덱스를 통해 개별 엑세스를 관리한다.
  - 업무상 필요한 시간 동안 이벤트를 보존할 수 있다.
- 이벤트 브로커는 메시지 브로커와 달리 데이터를 삭제 하지 않는다. 
- 이벤트 브로커는 서비스에서 나오는 이벤트를 큐에 저장한다.
  - 딱 한번 일어난 이벤트 데이터를 브로커에 저장함으로서, 단일 진실 공급원으로 사용 할 수 있다.
  - 장애가 발생 했을떄, 장애가 발생한 지점부터 재 처리 가능하다.
  - 많은 양의 스트림 데이터를 효과적으로 처리 할 수 있다.

메시지 브로커는 `레디스 큐`나 `래빗엠큐`, 이벤트 브로커는 `카프카`나 `키네시스`를 예로 들 수 있다. 

---
## ref
- https://www.inflearn.com/course/%EC%95%84%ED%8C%8C%EC%B9%98-%EC%B9%B4%ED%94%84%EC%B9%B4-%EC%9E%85%EB%AC%B8/dashboard
